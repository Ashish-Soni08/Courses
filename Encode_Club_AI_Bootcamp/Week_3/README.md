# Week 3: Local AI Model Deployment

- Running Large Language Models (LLMs) on personal hardware
- Utilizing cloud services for LLM execution
- Running AI models with Model Loaders
- Exploring open-source AI models
- Setting up the Text Generation WebUI tool
- Optimizing configurations for specific hardware
- Serving AI models through a local API
- Replacing OpenAI APIs with a compatible local alternative
- Developing a local AI storyteller application
